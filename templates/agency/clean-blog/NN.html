<!DOCTYPE html>
<html lang="en">

<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>NNs</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/clean-blog.min.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="http://maxcdn.bootstrapcdn.com/font-awesome/4.1.0/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='http://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>


    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand" href="agency/index2.html">Seam Consulting</a>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="index.html">Blog Home</a>
                    </li>
                    <!--li>
                        <a href="about.html">About</a>
                    </li>
                    <li>
                        <a href="post.html">Sample Post</a>
                    </li>
                    <li>
                        <a href="contact.html">Contact</a>
                    </li-->
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('img/chi4.png')">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <div class="post-heading">
                        <h1>Convolutional Neural Network on a GPU</h1>
                        <h2 class="subheading">Dropout CNN on the MNIST dataset</h2>
                        <span class="meta">Posted by <a href="#">Matt</a> on October 11, 2014</span>
                    </div>
                </div>
            </div>
        </div>
    </header>

    <!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <!--h2 class="section-heading">Setting up a GPU on an Amazon EC2 instance</h2-->
                    <blockquote>This part is assuming you have familiarity with Amazon AWS management and EC2 instances.</blockquote>
                    <p> Log into the AWS management console and head on over to EC2. From here, create an EC2 g2.2xlarge instance the same way you would create any other EC2 machine. Follow the instructions on Amazon and then ssh into your instance. </p>

                    <h2 class="section-heading">Setting up your GPU machine</h2>

                    <p><code>sudo apt-get update</code></p>

                    <p><code>sudo apt-get -y dist-upgrade</code></p>

                    <p><code>screen -S 'GPU SETUP'</code></p>

                    <p><code>sudo apt-get install -y gcc g++ gfortran build-essential git wget linux-image-generic libopenblas-dev python-dev python-pip python-nose python-numpy python-scipy</code></p>

                    <p><code>sudo pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git</code>



                    <p><code>sudo wget http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1404/x86_64/cuda-repo-ubuntu1404_6.5-14_amd64.deb</code></p>

                    <p><code>sudo dpkg -i cuda-repo-ubuntu1404_6.5-14_amd64.deb </code></p>

                    <p><code>sudo apt-get update</code></p>

                    <p><code>sudo apt-get install -y cuda </code></p>

                    <p><code>echo -e "\nexport PATH=/usr/local/cuda-6.5/bin:$PATH\n\nexport LD_LIBRARY_PATH=/usr/local/cuda-6.5/lib64" >> .bashrc</code></p> 

                    <p><code>sudo reboot</code></p>

                    <p><code>cuda-install-samples-6.5.sh ~/</code></p>

                    <p><code>echo -e "\n[global]\nfloatX=float32\ndevice=gpu\n[mode]=FAST_RUN\n\n[nvcc]\nfastmath=True\n\n[cuda]\nroot=/usr/local/cuda" >> ~/.theanorc</code> this sets up theano to use the gpu by default (not sure why you wouldn't to do this, but you might have your reasons). </p> 

                    <h2 class="section-heading">Testing your GPU machine</h2>

                    <p>A good way to test your GPU device is to use the tutorial from the <a href="http://deeplearning.net/software/theano/tutorial/using_gpu.html">GPU tutorial on Theano's website.</a></p>

                    <p>Copy and paste the script below into a script called check2.py.</p>

                    <div class="highlight-python"><div class="highlight"><pre><span class="kn">from</span> <span class="nn">theano</span> <span class="kn">import</span> <span class="n">function</span><span class="p">,</span> <span class="n">config</span><span class="p">,</span> <span class="n">shared</span><span class="p">,</span> <span class="n">sandbox</span>
<span class="kn">import</span> <span class="nn">theano.tensor</span> <span class="kn">as</span> <span class="nn">T</span>
<span class="kn">import</span> <span class="nn">numpy</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="n">vlen</span> <span class="o">=</span> <span class="mi">10</span> <span class="o">*</span> <span class="mi">30</span> <span class="o">*</span> <span class="mi">768</span>  <span class="c"># 10 x #cores x # threads per core</span>
<span class="n">iters</span> <span class="o">=</span> <span class="mi">1000</span>

<span class="n">rng</span> <span class="o">=</span> <span class="n">numpy</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">RandomState</span><span class="p">(</span><span class="mi">22</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">shared</span><span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">rng</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">vlen</span><span class="p">),</span> <span class="n">config</span><span class="o">.</span><span class="n">floatX</span><span class="p">))</span>
<span class="n">f</span> <span class="o">=</span> <span class="n">function</span><span class="p">([],</span> <span class="n">T</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="k">print</span> <span class="n">f</span><span class="o">.</span><span class="n">maker</span><span class="o">.</span><span class="n">fgraph</span><span class="o">.</span><span class="n">toposort</span><span class="p">()</span>
<span class="n">t0</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">xrange</span><span class="p">(</span><span class="n">iters</span><span class="p">):</span>
    <span class="n">r</span> <span class="o">=</span> <span class="n">f</span><span class="p">()</span>
<span class="n">t1</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="k">print</span> <span class="s">'Looping </span><span class="si">%d</span><span class="s"> times took'</span> <span class="o">%</span> <span class="n">iters</span><span class="p">,</span> <span class="n">t1</span> <span class="o">-</span> <span class="n">t0</span><span class="p">,</span> <span class="s">'seconds'</span>
<span class="k">print</span> <span class="s">'Result is'</span><span class="p">,</span> <span class="n">r</span>
<span class="k">if</span> <span class="n">numpy</span><span class="o">.</span><span class="n">any</span><span class="p">([</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">op</span><span class="p">,</span> <span class="n">T</span><span class="o">.</span><span class="n">Elemwise</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">f</span><span class="o">.</span><span class="n">maker</span><span class="o">.</span><span class="n">fgraph</span><span class="o">.</span><span class="n">toposort</span><span class="p">()]):</span>
    <span class="k">print</span> <span class="s">'Used the cpu'</span>
<span class="k">else</span><span class="p">:</span>
    <span class="k">print</span> <span class="s">'Used the gpu'</span>
</pre></div>
</div>
                    
                    <p>Run this code: <code>THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python check2.py</code>.   The output should look something like this: </p>

<div class="highlight-text"><div class="highlight"><pre>$ THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python check2.py
Using gpu device 0: GeForce GTX 580
[GpuElemwise{exp,no_inplace}(&lt;CudaNdarrayType(float32, vector)&gt;)]
Looping 1000 times took 0.34898686409 seconds
Result is &lt;CudaNdarray object at 0x6a7a5f0&gt;
Numpy result is [ 1.23178029  1.61879349  1.52278066 ...,  2.20771813  2.29967761
  1.62323296]
Used the gpu
</pre></div>
</div>



                    <h2 class="section-heading">The CNN Code</h2>

                    <p> The code below was inspired by the <a href="http://deeplearning.net/tutorial/lenet.html">LeNet-5</a> in combination with a very nice tutorial on neural networks <a href="http://snippyhollow.github.io/blog/2014/08/09/so-you-wanna-try-deep-learning/">from Gabriel Synnaeve's tutorial on Deep Learning</a>  

                    <!--a href="https://gist.github.com/KayneWest/052fa5a9143796ac468f"> Here is a direct link to the Github Gist</a-->
                    <script src="https://gist.github.com/KayneWest/052fa5a9143796ac468f.js"></script>
                    <!--script src="https://gist.github.com/KayneWest/052fa5a9143796ac468f.js"></script-->

                    <h2 class="section-heading">Running the ConvNet</h2>

                    <p>If you followed the GPU installation instructs, theano should use the GPU by default; for arguments sake, to run the code above, simply copy and paste code above into your favorite text editor and save it under the name CNN.py. Run: <code>THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python CNN.py into command line </code></p>

                    <p>It is important to realize that if you start to mess around with the actual network code, you need to make the network worthwhile to run on a gpu machine. Utilizing the power of the GPU reuires that the GPU has enough work to do.

                    <p>In my experience, getting good GPU performance heavily relies on making the data transfer to the GPU worthwhile by using theano's <code>shared</code> variables in conjunction with <code>float32</code> where applicable to store frequently accessed data, e.g. the weight matrix (especially considering that only operations with the<code>float32</code> data-type can be accelerated). 


                </div>
            </div>
        </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="https://twitter.com/SeamConsulting">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <p class="copyright text-muted">Copyright &copy; Seam Consulting 2014</p>
                </div>
            </div>
        </div>
    </footer>

    <script type="text/javascript" src="//ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/gist-embed/1.9/gist-embed.min.js"></script>


    <!-- jQuery -->
    <script src="js/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>

</body>

</html>
